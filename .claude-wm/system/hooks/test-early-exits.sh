#!/bin/bash

# Test script for early exit strategies in hooks
# This script tests various scenarios to ensure early exits work correctly

HOOKS_DIR="/Users/a.pezzotta/.claude/hooks"
TEST_DIR="/tmp/early-exit-tests"
LOG_FILE="/tmp/early-exit-test.log"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Test counter
TESTS_PASSED=0
TESTS_FAILED=0
TESTS_TOTAL=0

log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

run_test() {
    local test_name="$1"
    local test_command="$2"
    local expected_exit_code="$3"
    local should_be_fast="$4"
    
    TESTS_TOTAL=$((TESTS_TOTAL + 1))
    log "Running test: $test_name"
    
    start_time=$(date +%s%N)
    
    # Run the command and capture exit code
    eval "$test_command" > /tmp/test_output 2>&1
    actual_exit_code=$?
    
    end_time=$(date +%s%N)
    duration_ms=$(( (end_time - start_time) / 1000000 ))
    
    # Check exit code
    if [ "$actual_exit_code" = "$expected_exit_code" ]; then
        # Check if it was fast enough (if specified)
        if [ "$should_be_fast" = "true" ] && [ "$duration_ms" -gt 100 ]; then
            echo -e "${YELLOW}‚ö†Ô∏è  TEST SLOW: $test_name (${duration_ms}ms)${NC}"
            log "TEST SLOW: $test_name - Duration: ${duration_ms}ms (expected < 100ms)"
        else
            echo -e "${GREEN}‚úÖ PASS: $test_name (${duration_ms}ms)${NC}"
            log "TEST PASS: $test_name - Duration: ${duration_ms}ms"
            TESTS_PASSED=$((TESTS_PASSED + 1))
        fi
    else
        echo -e "${RED}‚ùå FAIL: $test_name - Expected exit code $expected_exit_code, got $actual_exit_code${NC}"
        log "TEST FAIL: $test_name - Expected exit code $expected_exit_code, got $actual_exit_code"
        cat /tmp/test_output
        TESTS_FAILED=$((TESTS_FAILED + 1))
    fi
    
    echo
}

# Setup test environment
setup_tests() {
    log "Setting up test environment..."
    
    # Create test directory
    rm -rf "$TEST_DIR"
    mkdir -p "$TEST_DIR"
    
    # Create test files
    mkdir -p "$TEST_DIR/app/page"
    mkdir -p "$TEST_DIR/components"
    mkdir -p "$TEST_DIR/utils"
    mkdir -p "$TEST_DIR/non-relevant"
    
    # Create relevant files
    echo "export default function Page() { return <div>Test</div>; }" > "$TEST_DIR/app/page/page.tsx"
    echo "export default function Component() { return <div>Test</div>; }" > "$TEST_DIR/components/TestComponent.tsx"
    echo "export function utilityFunction() { return 'test'; }" > "$TEST_DIR/utils/helper.ts"
    echo "const API_KEY = 'secret-key-123';" > "$TEST_DIR/utils/config.ts"
    echo "console.log('TODO: fix this');" > "$TEST_DIR/utils/debug.ts"
    
    # Create non-relevant files
    echo "This is a markdown file" > "$TEST_DIR/non-relevant/README.md"
    echo "body { color: red; }" > "$TEST_DIR/non-relevant/styles.css"
    echo "Random text content" > "$TEST_DIR/non-relevant/data.txt"
    
    # Create binary-like file
    echo -e "\x00\x01\x02\x03" > "$TEST_DIR/non-relevant/binary.bin"
    
    # Create generated file
    echo "// Code generated by protoc-gen-go" > "$TEST_DIR/generated.go"
    echo "package main" >> "$TEST_DIR/generated.go"
    
    log "Test environment setup complete"
}

# Test Security Validator Early Exits
test_security_validator() {
    log "Testing Security Validator early exits..."
    
    # Test 1: Should skip non-security files quickly
    run_test "Security: Skip CSS file" \
        "echo '{\"tool_name\":\"Write\",\"tool_input\":{\"file_path\":\"$TEST_DIR/non-relevant/styles.css\",\"content\":\"body { color: red; }\"}}' | $HOOKS_DIR/security-validator" \
        "0" "true"
    
    # Test 2: Should skip files with no content
    run_test "Security: Skip empty content" \
        "echo '{\"tool_name\":\"Write\",\"tool_input\":{\"file_path\":\"$TEST_DIR/utils/config.ts\",\"content\":\"\"}}' | $HOOKS_DIR/security-validator" \
        "0" "true"
    
    # Test 3: Should process security-relevant files
    run_test "Security: Process .env file" \
        "echo '{\"tool_name\":\"Write\",\"tool_input\":{\"file_path\":\"$TEST_DIR/.env\",\"content\":\"API_KEY=secret-key-123\"}}' | $HOOKS_DIR/security-validator" \
        "0" "false"
    
    # Test 4: Should process config files
    run_test "Security: Process config file" \
        "echo '{\"tool_name\":\"Write\",\"tool_input\":{\"file_path\":\"$TEST_DIR/utils/config.ts\",\"content\":\"const API_KEY = 'secret-key-123';\"}}' | $HOOKS_DIR/security-validator" \
        "0" "false"
}

# Test Code Quality Validator Early Exits
test_code_quality_validator() {
    log "Testing Code Quality Validator early exits..."
    
    # Test 1: Should skip binary files
    run_test "Quality: Skip binary file" \
        "$HOOKS_DIR/code-quality-validator $TEST_DIR/non-relevant/binary.bin" \
        "0" "true"
    
    # Test 2: Should skip generated files
    run_test "Quality: Skip generated file" \
        "$HOOKS_DIR/code-quality-validator $TEST_DIR/generated.go" \
        "0" "true"
    
    # Test 3: Should skip empty files
    echo "" > "$TEST_DIR/empty.ts"
    run_test "Quality: Skip empty file" \
        "$HOOKS_DIR/code-quality-validator $TEST_DIR/empty.ts" \
        "0" "true"
    
    # Test 4: Should process relevant files
    run_test "Quality: Process TypeScript file" \
        "$HOOKS_DIR/code-quality-validator $TEST_DIR/utils/helper.ts" \
        "0" "false"
}

# Test Duplicate Detector Early Exits
test_duplicate_detector() {
    log "Testing Duplicate Detector early exits..."
    
    # Test 1: Should skip non-code files
    run_test "Duplicate: Skip text file" \
        "echo '{\"tool_name\":\"Write\",\"tool_input\":{\"file_path\":\"$TEST_DIR/non-relevant/data.txt\"}}' | $HOOKS_DIR/duplicate-detector-go" \
        "0" "true"
    
    # Test 2: Should skip CSS files
    run_test "Duplicate: Skip CSS file" \
        "echo '{\"tool_name\":\"Write\",\"tool_input\":{\"file_path\":\"$TEST_DIR/non-relevant/styles.css\"}}' | $HOOKS_DIR/duplicate-detector-go" \
        "0" "true"
    
    # Test 3: Should process relevant files
    run_test "Duplicate: Process component file" \
        "echo '{\"tool_name\":\"Write\",\"tool_input\":{\"file_path\":\"$TEST_DIR/components/NewComponent.tsx\"}}' | $HOOKS_DIR/duplicate-detector-go" \
        "0" "false"
    
    # Test 4: Should process page files
    run_test "Duplicate: Process page file" \
        "echo '{\"tool_name\":\"Write\",\"tool_input\":{\"file_path\":\"$TEST_DIR/app/newpage/page.tsx\"}}' | $HOOKS_DIR/duplicate-detector-go" \
        "0" "false"
}

# Test performance impact
test_performance_impact() {
    log "Testing performance impact of early exits..."
    
    # Create a large number of non-relevant files
    for i in {1..100}; do
        echo "body { color: red; }" > "$TEST_DIR/non-relevant/styles$i.css"
        echo "Random text content $i" > "$TEST_DIR/non-relevant/data$i.txt"
    done
    
    # Test bulk skipping performance
    start_time=$(date +%s%N)
    
    for i in {1..10}; do
        echo "{\"tool_name\":\"Write\",\"tool_input\":{\"file_path\":\"$TEST_DIR/non-relevant/styles$i.css\",\"content\":\"body { color: red; }\"}}" | $HOOKS_DIR/security-validator > /dev/null 2>&1
    done
    
    end_time=$(date +%s%N)
    duration_ms=$(( (end_time - start_time) / 1000000 ))
    
    log "Bulk skip performance: ${duration_ms}ms for 10 files"
    
    if [ "$duration_ms" -lt 500 ]; then
        echo -e "${GREEN}‚úÖ PERFORMANCE: Bulk skip under 500ms (${duration_ms}ms)${NC}"
        TESTS_PASSED=$((TESTS_PASSED + 1))
    else
        echo -e "${RED}‚ùå PERFORMANCE: Bulk skip too slow (${duration_ms}ms)${NC}"
        TESTS_FAILED=$((TESTS_FAILED + 1))
    fi
    
    TESTS_TOTAL=$((TESTS_TOTAL + 1))
}

# Main execution
main() {
    log "Starting Early Exit Strategy Tests"
    echo "Early Exit Strategy Tests"
    echo "=========================="
    echo
    
    # Setup
    setup_tests
    
    # Run tests
    test_security_validator
    test_code_quality_validator
    test_duplicate_detector
    test_performance_impact
    
    # Summary
    echo
    echo "Test Results Summary:"
    echo "===================="
    echo -e "Total Tests: $TESTS_TOTAL"
    echo -e "${GREEN}Passed: $TESTS_PASSED${NC}"
    echo -e "${RED}Failed: $TESTS_FAILED${NC}"
    
    if [ $TESTS_FAILED -eq 0 ]; then
        echo -e "${GREEN}üéâ All tests passed!${NC}"
        log "All tests passed successfully"
    else
        echo -e "${RED}‚ùå Some tests failed. Check log for details.${NC}"
        log "Tests completed with $TESTS_FAILED failures"
    fi
    
    echo
    echo "Log file: $LOG_FILE"
    
    # Cleanup
    rm -rf "$TEST_DIR"
    rm -f /tmp/test_output
    
    exit $TESTS_FAILED
}

# Run main function
main "$@"