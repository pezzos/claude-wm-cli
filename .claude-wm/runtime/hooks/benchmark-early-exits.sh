#!/bin/bash

# Benchmark script to measure performance impact of early exit strategies
# This script compares performance with and without early exits

HOOKS_DIR="/Users/a.pezzotta/.claude/hooks"
TEST_DIR="/tmp/early-exit-benchmark"
RESULTS_FILE="/tmp/early-exit-benchmark-results.json"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log() {
    echo -e "${BLUE}[$(date '+%H:%M:%S')]${NC} $1"
}

# Create test environment with various file types
setup_benchmark_env() {
    log "Setting up benchmark environment..."
    
    rm -rf "$TEST_DIR"
    mkdir -p "$TEST_DIR"
    
    # Create directories
    mkdir -p "$TEST_DIR/app/dashboard"
    mkdir -p "$TEST_DIR/app/api/users"
    mkdir -p "$TEST_DIR/components/ui"
    mkdir -p "$TEST_DIR/utils"
    mkdir -p "$TEST_DIR/lib"
    mkdir -p "$TEST_DIR/styles"
    mkdir -p "$TEST_DIR/docs"
    mkdir -p "$TEST_DIR/assets"
    mkdir -p "$TEST_DIR/dist"
    mkdir -p "$TEST_DIR/node_modules"
    
    # Create relevant files (should be processed)
    echo "export default function Dashboard() { return <div>Dashboard</div>; }" > "$TEST_DIR/app/dashboard/page.tsx"
    echo "export default function API() { return NextResponse.json({}); }" > "$TEST_DIR/app/api/users/route.ts"
    echo "export default function Button() { return <button>Click</button>; }" > "$TEST_DIR/components/ui/Button.tsx"
    echo "export function formatDate(date: Date) { return date.toISOString(); }" > "$TEST_DIR/utils/dateUtils.ts"
    echo "export const config = { apiUrl: 'https://api.example.com' };" > "$TEST_DIR/lib/config.ts"
    echo "const API_KEY = 'secret-key-123';" > "$TEST_DIR/lib/secrets.ts"
    
    # Create irrelevant files (should be skipped)
    for i in {1..50}; do
        echo "body { color: red; }" > "$TEST_DIR/styles/style$i.css"
        echo "# Documentation $i" > "$TEST_DIR/docs/doc$i.md"
        echo "Random text content $i" > "$TEST_DIR/assets/data$i.txt"
        echo "Generated content $i" > "$TEST_DIR/dist/bundle$i.js"
        echo "module.exports = {};" > "$TEST_DIR/node_modules/module$i.js"
    done
    
    # Create binary files
    for i in {1..20}; do
        echo -e "\x00\x01\x02\x03" > "$TEST_DIR/assets/binary$i.bin"
    done
    
    # Create generated files
    for i in {1..10}; do
        echo "// Code generated by protoc-gen-go" > "$TEST_DIR/generated$i.go"
        echo "package main" >> "$TEST_DIR/generated$i.go"
    done
    
    log "Created test environment with $(find "$TEST_DIR" -type f | wc -l) files"
}

# Benchmark function
benchmark_hook() {
    local hook_name="$1"
    local hook_path="$2"
    local test_input="$3"
    local description="$4"
    
    # Don't log during benchmarking to avoid interfering with output
    
    local total_time=0
    local iterations=10
    
    for i in $(seq 1 $iterations); do
        start_time=$(date +%s%N)
        
        echo "$test_input" | $hook_path > /dev/null 2>&1
        
        end_time=$(date +%s%N)
        duration=$(( (end_time - start_time) / 1000000 ))
        total_time=$((total_time + duration))
    done
    
    local avg_time=$((total_time / iterations))
    echo "$avg_time"
}

# Run benchmarks
run_benchmarks() {
    log "Running performance benchmarks..."
    
    # Initialize results
    cat > "$RESULTS_FILE" << EOF
{
    "benchmark_date": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
    "total_files": $(find "$TEST_DIR" -type f | wc -l),
    "results": {
EOF
    
    # Security Validator Benchmarks
    log "Benchmarking Security Validator..."
    
    # Test 1: Skip CSS file (should be very fast)
    css_time=$(benchmark_hook "Security Validator" "$HOOKS_DIR/security-validator" \
        '{"tool_name":"Write","tool_input":{"file_path":"'"$TEST_DIR/styles/style1.css"'","content":"body { color: red; }"}}' \
        "Skip CSS file")
    
    # Test 2: Process config file (should be normal speed)
    config_time=$(benchmark_hook "Security Validator" "$HOOKS_DIR/security-validator" \
        '{"tool_name":"Write","tool_input":{"file_path":"'"$TEST_DIR/lib/config.ts"'","content":"const API_KEY = '\''secret-key-123'\'';"}}' \
        "Process config file")
    
    # Test 3: Skip empty content (should be very fast)
    empty_time=$(benchmark_hook "Security Validator" "$HOOKS_DIR/security-validator" \
        '{"tool_name":"Write","tool_input":{"file_path":"'"$TEST_DIR/lib/config.ts"'","content":""}}' \
        "Skip empty content")
    
    # Code Quality Validator Benchmarks
    log "Benchmarking Code Quality Validator..."
    
    # Test 1: Skip binary file (should be very fast)
    binary_time=$(benchmark_hook "Code Quality Validator" "$HOOKS_DIR/code-quality-validator" \
        "$TEST_DIR/assets/binary1.bin" \
        "Skip binary file")
    
    # Test 2: Skip generated file (should be very fast)
    generated_time=$(benchmark_hook "Code Quality Validator" "$HOOKS_DIR/code-quality-validator" \
        "$TEST_DIR/generated1.go" \
        "Skip generated file")
    
    # Test 3: Process TypeScript file (should be normal speed)
    ts_time=$(benchmark_hook "Code Quality Validator" "$HOOKS_DIR/code-quality-validator" \
        "$TEST_DIR/utils/dateUtils.ts" \
        "Process TypeScript file")
    
    # Duplicate Detector Benchmarks
    log "Benchmarking Duplicate Detector..."
    
    # Test 1: Skip text file (should be very fast)
    txt_time=$(benchmark_hook "Duplicate Detector" "$HOOKS_DIR/duplicate-detector-go" \
        '{"tool_name":"Write","tool_input":{"file_path":"'"$TEST_DIR/assets/data1.txt"'"}}' \
        "Skip text file")
    
    # Test 2: Skip CSS file (should be very fast)
    css_dup_time=$(benchmark_hook "Duplicate Detector" "$HOOKS_DIR/duplicate-detector-go" \
        '{"tool_name":"Write","tool_input":{"file_path":"'"$TEST_DIR/styles/style1.css"'"}}' \
        "Skip CSS file")
    
    # Test 3: Process component file (should be normal speed)
    component_time=$(benchmark_hook "Duplicate Detector" "$HOOKS_DIR/duplicate-detector-go" \
        '{"tool_name":"Write","tool_input":{"file_path":"'"$TEST_DIR/components/ui/NewButton.tsx"'"}}' \
        "Process component file")
    
    # Write results to JSON
    cat >> "$RESULTS_FILE" << EOF
        "security_validator": {
            "skip_css_file": ${css_time},
            "process_config_file": ${config_time},
            "skip_empty_content": ${empty_time}
        },
        "code_quality_validator": {
            "skip_binary_file": ${binary_time},
            "skip_generated_file": ${generated_time},
            "process_typescript_file": ${ts_time}
        },
        "duplicate_detector": {
            "skip_text_file": ${txt_time},
            "skip_css_file": ${css_dup_time},
            "process_component_file": ${component_time}
        }
    }
}
EOF
    
    # Calculate and display results
    log "Benchmark Results (average of 10 runs):"
    echo
    echo -e "${GREEN}Security Validator:${NC}"
    echo -e "  Skip CSS file:        ${css_time}ms"
    echo -e "  Process config file:  ${config_time}ms"
    echo -e "  Skip empty content:   ${empty_time}ms"
    echo
    echo -e "${GREEN}Code Quality Validator:${NC}"
    echo -e "  Skip binary file:     ${binary_time}ms"
    echo -e "  Skip generated file:  ${generated_time}ms"
    echo -e "  Process TypeScript:   ${ts_time}ms"
    echo
    echo -e "${GREEN}Duplicate Detector:${NC}"
    echo -e "  Skip text file:       ${txt_time}ms"
    echo -e "  Skip CSS file:        ${css_dup_time}ms"
    echo -e "  Process component:    ${component_time}ms"
    echo
    
    # Calculate efficiency gains
    security_skip_avg=$(( (css_time + empty_time) / 2 ))
    security_process_avg=$config_time
    security_gain=$(( (security_process_avg - security_skip_avg) * 100 / security_process_avg ))
    
    quality_skip_avg=$(( (binary_time + generated_time) / 2 ))
    quality_process_avg=$ts_time
    quality_gain=$(( (quality_process_avg - quality_skip_avg) * 100 / quality_process_avg ))
    
    duplicate_skip_avg=$(( (txt_time + css_dup_time) / 2 ))
    duplicate_process_avg=$component_time
    duplicate_gain=$(( (duplicate_process_avg - duplicate_skip_avg) * 100 / duplicate_process_avg ))
    
    echo -e "${YELLOW}Performance Gains:${NC}"
    echo -e "  Security Validator:     ${security_gain}% faster for skipped files"
    echo -e "  Code Quality Validator: ${quality_gain}% faster for skipped files"
    echo -e "  Duplicate Detector:     ${duplicate_gain}% faster for skipped files"
    echo
    
    # Overall assessment
    local total_skip_time=$((security_skip_avg + quality_skip_avg + duplicate_skip_avg))
    local total_process_time=$((security_process_avg + quality_process_avg + duplicate_process_avg))
    local overall_gain=$(( (total_process_time - total_skip_time) * 100 / total_process_time ))
    
    echo -e "${GREEN}Overall Early Exit Impact:${NC}"
    echo -e "  Average skip time:    ${total_skip_time}ms"
    echo -e "  Average process time: ${total_process_time}ms"
    echo -e "  Overall improvement:  ${overall_gain}%"
    echo
    
    if [ $overall_gain -gt 15 ]; then
        echo -e "${GREEN}✅ Early exits provide significant performance improvement (${overall_gain}%)${NC}"
    elif [ $overall_gain -gt 5 ]; then
        echo -e "${YELLOW}⚠️  Early exits provide moderate performance improvement (${overall_gain}%)${NC}"
    else
        echo -e "${RED}❌ Early exits provide minimal performance improvement (${overall_gain}%)${NC}"
    fi
}

# Bulk processing benchmark
bulk_processing_benchmark() {
    log "Running bulk processing benchmark..."
    
    # Create test files
    local relevant_files=()
    local irrelevant_files=()
    
    # Create more test files
    for i in {1..20}; do
        echo "export const value$i = 'test';" > "$TEST_DIR/relevant$i.ts"
        relevant_files+=("$TEST_DIR/relevant$i.ts")
        
        echo "Random content $i" > "$TEST_DIR/irrelevant$i.txt"
        irrelevant_files+=("$TEST_DIR/irrelevant$i.txt")
    done
    
    # Benchmark processing relevant files
    log "Benchmarking relevant files processing..."
    start_time=$(date +%s%N)
    
    for file in "${relevant_files[@]}"; do
        echo '{"tool_name":"Write","tool_input":{"file_path":"'$file'","content":"export const value = '\''test'\'';"}}' | $HOOKS_DIR/security-validator > /dev/null 2>&1
    done
    
    end_time=$(date +%s%N)
    relevant_time=$(( (end_time - start_time) / 1000000 ))
    
    # Benchmark processing irrelevant files
    log "Benchmarking irrelevant files processing..."
    start_time=$(date +%s%N)
    
    for file in "${irrelevant_files[@]}"; do
        echo '{"tool_name":"Write","tool_input":{"file_path":"'$file'","content":"Random content"}}' | $HOOKS_DIR/security-validator > /dev/null 2>&1
    done
    
    end_time=$(date +%s%N)
    irrelevant_time=$(( (end_time - start_time) / 1000000 ))
    
    echo
    echo -e "${GREEN}Bulk Processing Results:${NC}"
    echo -e "  20 relevant files:   ${relevant_time}ms"
    echo -e "  20 irrelevant files: ${irrelevant_time}ms"
    echo -e "  Time saved:          $((relevant_time - irrelevant_time))ms"
    echo -e "  Efficiency gain:     $(( (relevant_time - irrelevant_time) * 100 / relevant_time ))%"
}

# Main execution
main() {
    echo "Early Exit Performance Benchmark"
    echo "================================="
    echo
    
    setup_benchmark_env
    run_benchmarks
    bulk_processing_benchmark
    
    echo
    echo -e "${BLUE}Results saved to: ${RESULTS_FILE}${NC}"
    echo -e "${BLUE}Test environment: ${TEST_DIR}${NC}"
    
    # Cleanup
    rm -rf "$TEST_DIR"
    
    log "Benchmark completed successfully"
}

# Run main function
main "$@"